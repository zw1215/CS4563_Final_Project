{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "import scipy\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameFile = open(\"features.txt\")\n",
    "nameList = []\n",
    "for feature in nameFile:\n",
    "    feature = feature.strip()\n",
    "    nameList.append(feature)\n",
    "\n",
    "    \n",
    "X_train = pd.read_csv(\"cleaned_X_train.csv\", names = nameList)\n",
    "X_test = pd.read_csv(\"cleaned_X_test.csv\", names = nameList)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "\n",
    "y_train = pd.read_csv(\"y_train.csv\", names = [\"Action\"])\n",
    "y_test = pd.read_csv(\"y_test.csv\", names = [\"Action\"])\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7767,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(w,z,gamma):\n",
    "    d = w - z\n",
    "    return np.exp(-gamma*np.sum(d*d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7767, 7767)\n"
     ]
    }
   ],
   "source": [
    "K = pairwise_kernels(X_train, metric = 'rbf', gamma = .05)\n",
    "print(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum similarities: \n",
      " [0.39009221571106545, 0.332786181248158, 0.3221287097647293, 0.3179946907071938, 0.31422658666043557, 0.31148442099116647, 0.30703010753425686, 0.3062282131938721, 0.30440608482184983, 0.3036318398212423]\n",
      "Minimum similarities: \n",
      " [1.5416430089433268e-18, 3.4228311243882322e-18, 1.4770790140620293e-14, 1.7541174314854206e-13, 3.8017269485076573e-13, 7.916168974764486e-13, 1.6527249327485234e-12, 1.823933878710029e-12, 6.605868992055673e-12, 1.1854790023685458e-11]\n"
     ]
    }
   ],
   "source": [
    "lrg_lst = []\n",
    "sml_lst = []\n",
    "for i in range(1, 7767):\n",
    "    cur_k = rbf_kernel(X_train[0], X_train[i], .05)\n",
    "    if(len(lrg_lst) == 10):\n",
    "        lrg_lst.sort(reverse = True)\n",
    "        sml_lst.sort()\n",
    "    if(len(lrg_lst) < 10):\n",
    "        lrg_lst.append(cur_k)\n",
    "        sml_lst.append(cur_k)\n",
    "    \n",
    "    else:\n",
    "        if cur_k > lrg_lst[9]:\n",
    "            lrg_lst.append(cur_k)\n",
    "            lrg_lst.sort(reverse = True)\n",
    "            lrg_lst.pop()\n",
    "        if cur_k < sml_lst[9]:\n",
    "            sml_lst.append(cur_k)\n",
    "            sml_lst.sort()\n",
    "            sml_lst.pop()\n",
    "            \n",
    "print('Maximum similarities: \\n', [e for e in lrg_lst])\n",
    "print('Minimum similarities: \\n', [e for e in sml_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_opt_adapt(grad_func, beta0, nit=7767, lr_init=1e-3):\n",
    "    beta = beta0\n",
    "    lr = lr_init\n",
    "    L,Lgrad = grad_func(beta0)\n",
    "    for it in range(nit):\n",
    "        beta1 = beta - lr*Lgrad\n",
    "        L1, Lgrad1 = grad_func(beta1)\n",
    "        df_est = Lgrad.T@(beta1-beta)\n",
    "        alpha = 0.5\n",
    "        if (L1-L < alpha*df_est) and (L1 < L):\n",
    "            lr = lr*2\n",
    "            L = L1\n",
    "            Lgrad = Lgrad1\n",
    "            beta = beta1\n",
    "        else:\n",
    "            lr = lr/2 \n",
    "        if (lr < 1e-15):\n",
    "            break;\n",
    "    return beta\n",
    "\n",
    "# note that I'm taking a slightly different approach here to what we did in `lab_grad_descent`.\n",
    "# happy discuss if there are any questions. The approach here will lead to faster convergence.\n",
    "def kernel_grad(alpha,K,y,lamb):\n",
    "    z = K@alpha\n",
    "    h = 1/(1+np.exp(-z))\n",
    "    L = np.sum((1-y)*z - np.log(h)) + lamb*np.sum(z*alpha)\n",
    "\n",
    "    # Gradient\n",
    "    Lgrad = (h-y) + 2*lamb*alpha\n",
    "    return L, Lgrad\n",
    "\n",
    "def log_fit(K,y,lamb,nit=1000):\n",
    "    \"\"\"\n",
    "    Function which minizes the logistic regression loss \n",
    "    \"\"\"\n",
    "    kernel_grad_eval = lambda alpha: kernel_grad(alpha,K,y,lamb)\n",
    "    alpha0 = np.zeros(K.shape[0])\n",
    "    alpha = grad_opt_adapt(kernel_grad_eval, alpha0, nit=nit, lr_init=1e-5)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha is [7.52708738e+150 7.52708738e+150 7.52708738e+150 ... 1.88177184e+150\n",
      " 1.88177184e+150 1.88177184e+150]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = log_fit(K, y_train, 0, 7767)\n",
    "print(\"alpha is\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ktest = pairwise_kernels(X_test, X_train, metric = 'rbf', gamma = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.40983624e+153 4.94783924e+153 7.17195179e+153 ... 1.25975625e+153\n",
      " 1.28127574e+153 1.29980985e+153]\n",
      "Test accuracy = 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "yhat = (Ktest.dot(alpha))\n",
    "print(yhat)\n",
    "\n",
    "acc = np.mean(yhat == y_train)\n",
    "print(\"Test accuracy = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
